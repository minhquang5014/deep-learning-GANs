{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.layers import Flatten, Conv2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING IN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping file 666.jpg as it cannot be identified as an image.\n",
      "cat images uploaded\n",
      "Warning: Skipping file 11702.jpg as it cannot be identified as an image.\n",
      "dog images uploaded\n"
     ]
    }
   ],
   "source": [
    "from PIL import UnidentifiedImageError\n",
    "def load_data(dir, img_size):\n",
    "    images = []\n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith(\"jpg\") or filename.endswith(\"png\"):\n",
    "            try:\n",
    "                img = load_img(os.path.join(dir, filename), target_size=(img_size, img_size))\n",
    "                img = img_to_array(img)\n",
    "                img = (img - 127.5) / 127.5  # normalize to [-1, 1]\n",
    "                images.append(img)\n",
    "            except UnidentifiedImageError:\n",
    "                print(f\"Warning: Skipping file {filename} as it cannot be identified as an image.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e} with file {filename}\")\n",
    "    return np.array(images)\n",
    "\n",
    "cat = load_data('PetImages/Cat/', 64)\n",
    "print(\"cat images uploaded\")\n",
    "dog = load_data('PetImages/Dog/', 64)\n",
    "print(\"dog images uploaded\")\n",
    "data = np.concatenate([cat, dog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.60784316  0.3019608  -0.3019608 ]\n",
      "  [ 0.6627451   0.35686275 -0.24705882]\n",
      "  [ 0.73333335  0.4117647  -0.20784314]\n",
      "  ...\n",
      "  [ 0.9372549   0.6784314   0.07450981]\n",
      "  [ 0.92156863  0.6313726  -0.00392157]\n",
      "  [ 0.8901961   0.58431375 -0.03529412]]\n",
      "\n",
      " [[ 0.6156863   0.30980393 -0.29411766]\n",
      "  [ 0.67058825  0.3647059  -0.23921569]\n",
      "  [ 0.73333335  0.4117647  -0.20784314]\n",
      "  ...\n",
      "  [ 0.94509804  0.69411767  0.10588235]\n",
      "  [ 0.9372549   0.654902    0.04313726]\n",
      "  [ 0.92156863  0.6156863  -0.00392157]]\n",
      "\n",
      " [[ 0.6156863   0.30980393 -0.29411766]\n",
      "  [ 0.67058825  0.3647059  -0.23921569]\n",
      "  [ 0.73333335  0.4117647  -0.20784314]\n",
      "  ...\n",
      "  [ 0.92941177  0.69411767  0.12156863]\n",
      "  [ 0.94509804  0.69411767  0.09019608]\n",
      "  [ 0.9372549   0.6313726   0.01176471]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.27058825 -0.00392157 -0.5372549 ]\n",
      "  [ 0.3019608   0.02745098 -0.5058824 ]\n",
      "  [ 0.34117648  0.05098039 -0.5058824 ]\n",
      "  ...\n",
      "  [-0.9764706  -0.96862745 -1.        ]\n",
      "  [-0.9764706  -0.96862745 -1.        ]\n",
      "  [-0.9843137  -0.9764706  -1.        ]]\n",
      "\n",
      " [[ 0.25490198 -0.01960784 -0.5529412 ]\n",
      "  [ 0.27058825 -0.00392157 -0.5372549 ]\n",
      "  [ 0.30980393  0.01960784 -0.5372549 ]\n",
      "  ...\n",
      "  [-0.9764706  -0.96862745 -1.        ]\n",
      "  [-0.9764706  -0.96862745 -1.        ]\n",
      "  [-0.9843137  -0.9764706  -1.        ]]\n",
      "\n",
      " [[ 0.2        -0.04313726 -0.5686275 ]\n",
      "  [ 0.23921569 -0.00392157 -0.5294118 ]\n",
      "  [ 0.28627452  0.01960784 -0.54509807]\n",
      "  ...\n",
      "  [-0.9843137  -0.9843137  -1.        ]\n",
      "  [-0.9843137  -0.9843137  -1.        ]\n",
      "  [-0.9843137  -0.9843137  -1.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD GENERATOR AND DISCRIMINATOR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128 * 8* 8, input_dim=latent_dim, activation='relu'))\n",
    "    model.add(Reshape((8, 8, 128)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2DTranspose(3, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    return model\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, input_shape=img_shape,padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def compile_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    z = Input(shape=(latent_dim,))\n",
    "    img = generator(z)\n",
    "    validity = discriminator(img)\n",
    "\n",
    "    combined = Model(z, validity)\n",
    "    combined.compile(loss=\"binary_crossentropy\", optimizer=Adam())\n",
    "    return combined\n",
    "\n",
    "latent_dim =100\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator((64, 64, 3))\n",
    "gan = compile_gan(generator, discriminator)\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", \n",
    "                          optimizer=Adam(),\n",
    "                          metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000002261A56FF60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x0000022669FD5580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0 [D loss: 0.5233521461486816 | D accuracy: 49.21875] [G loss: [array(0.56278044, dtype=float32), array(0.56278044, dtype=float32), array(0.421875, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "1 [D loss: 0.4857025146484375 | D accuracy: 49.270832538604736] [G loss: [array(0.5203454, dtype=float32), array(0.5203454, dtype=float32), array(0.44791666, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "2 [D loss: 0.469914048910141 | D accuracy: 49.38616156578064] [G loss: [array(0.49370623, dtype=float32), array(0.49370623, dtype=float32), array(0.4609375, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "3 [D loss: 0.4530823230743408 | D accuracy: 49.47916567325592] [G loss: [array(0.4672509, dtype=float32), array(0.4672509, dtype=float32), array(0.46875, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "4 [D loss: 0.4318947196006775 | D accuracy: 53.716856241226196] [G loss: [array(0.43893734, dtype=float32), array(0.43893734, dtype=float32), array(0.5572917, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
      "5 [D loss: 0.4074140787124634 | D accuracy: 60.594093799591064] [G loss: [array(0.40949106, dtype=float32), array(0.40949106, dtype=float32), array(0.62053573, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "6 [D loss: 0.3804834485054016 | D accuracy: 65.69010019302368] [G loss: [array(0.3787276, dtype=float32), array(0.3787276, dtype=float32), array(0.66796875, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "7 [D loss: 0.35191988945007324 | D accuracy: 69.61805820465088] [G loss: [array(0.34708956, dtype=float32), array(0.34708956, dtype=float32), array(0.7048611, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "8 [D loss: 0.32285159826278687 | D accuracy: 72.7384865283966] [G loss: [array(0.31667703, dtype=float32), array(0.31667703, dtype=float32), array(0.734375, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "9 [D loss: 0.29688698053359985 | D accuracy: 75.27732849121094] [G loss: [array(0.29091552, dtype=float32), array(0.29091552, dtype=float32), array(0.75852275, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "10 [D loss: 0.273270845413208 | D accuracy: 77.38337516784668] [G loss: [array(0.26799855, dtype=float32), array(0.26799855, dtype=float32), array(0.7786458, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "11 [D loss: 0.2529919743537903 | D accuracy: 79.15865182876587] [G loss: [array(0.24847469, dtype=float32), array(0.24847469, dtype=float32), array(0.7956731, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
      "12 [D loss: 0.2354973554611206 | D accuracy: 80.67542910575867] [G loss: [array(0.23156895, dtype=float32), array(0.23156895, dtype=float32), array(0.81026787, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "13 [D loss: 0.2228223830461502 | D accuracy: 81.93336725234985] [G loss: [array(0.21982951, dtype=float32), array(0.21982951, dtype=float32), array(0.82239586, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
      "14 [D loss: 0.20979854464530945 | D accuracy: 83.0810546875] [G loss: [array(0.2067917, dtype=float32), array(0.2067917, dtype=float32), array(0.8334961, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "15 [D loss: 0.19873151183128357 | D accuracy: 84.0449571609497] [G loss: [array(0.19580118, dtype=float32), array(0.19580118, dtype=float32), array(0.8428309, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step\n",
      "16 [D loss: 0.18766087293624878 | D accuracy: 84.94420051574707] [G loss: [array(0.18504773, dtype=float32), array(0.18504773, dtype=float32), array(0.8515625, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
      "17 [D loss: 0.1778765618801117 | D accuracy: 85.7474684715271] [G loss: [array(0.17565176, dtype=float32), array(0.17565176, dtype=float32), array(0.859375, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "18 [D loss: 0.17005771398544312 | D accuracy: 86.4297866821289] [G loss: [array(0.16790757, dtype=float32), array(0.16790757, dtype=float32), array(0.8660156, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "19 [D loss: 0.16239666938781738 | D accuracy: 87.04631328582764] [G loss: [array(0.16045065, dtype=float32), array(0.16045065, dtype=float32), array(0.8720238, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "20 [D loss: 0.16086819767951965 | D accuracy: 87.42897510528564] [G loss: [array(0.16501623, dtype=float32), array(0.16501623, dtype=float32), array(0.87357956, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "21 [D loss: 0.15965253114700317 | D accuracy: 87.7732515335083] [G loss: [array(0.1578981, dtype=float32), array(0.1578981, dtype=float32), array(0.87907606, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "22 [D loss: 0.15609243512153625 | D accuracy: 88.18948268890381] [G loss: [array(0.15444936, dtype=float32), array(0.15444936, dtype=float32), array(0.883138, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "23 [D loss: 0.1579170972108841 | D accuracy: 88.3826494216919] [G loss: [array(0.15632197, dtype=float32), array(0.15632197, dtype=float32), array(0.885, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "24 [D loss: 0.1523129940032959 | D accuracy: 88.8035535812378] [G loss: [array(0.15083422, dtype=float32), array(0.15083422, dtype=float32), array(0.8891226, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "25 [D loss: 0.14673811197280884 | D accuracy: 89.22219276428223] [G loss: [array(0.14536673, dtype=float32), array(0.14536673, dtype=float32), array(0.8932292, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "26 [D loss: 0.14145100116729736 | D accuracy: 89.61064219474792] [G loss: [array(0.14017667, dtype=float32), array(0.14017667, dtype=float32), array(0.8970424, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "27 [D loss: 0.13657909631729126 | D accuracy: 89.97206687927246] [G loss: [array(0.13539146, dtype=float32), array(0.13539146, dtype=float32), array(0.9005927, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "28 [D loss: 0.1319890320301056 | D accuracy: 90.30919075012207] [G loss: [array(0.13087988, dtype=float32), array(0.13087988, dtype=float32), array(0.9039062, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "29 [D loss: 0.12770184874534607 | D accuracy: 90.62438011169434] [G loss: [array(0.12666363, dtype=float32), array(0.12666363, dtype=float32), array(0.907006, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "30 [D loss: 0.1237141340970993 | D accuracy: 90.91970920562744] [G loss: [array(0.12277509, dtype=float32), array(0.12277509, dtype=float32), array(0.9099121, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "31 [D loss: 0.17601853609085083 | D accuracy: 90.4394268989563] [G loss: [array(0.23104501, dtype=float32), array(0.23104501, dtype=float32), array(0.8974905, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "32 [D loss: 0.22592508792877197 | D accuracy: 89.97629880905151] [G loss: [array(0.22425157, dtype=float32), array(0.22425157, dtype=float32), array(0.90050554, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "33 [D loss: 0.2231752872467041 | D accuracy: 90.1748538017273] [G loss: [array(0.2215697, dtype=float32), array(0.2215697, dtype=float32), array(0.90245533, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "34 [D loss: 0.2205752730369568 | D accuracy: 90.3841495513916] [G loss: [array(0.21903278, dtype=float32), array(0.21903278, dtype=float32), array(0.9045139, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "35 [D loss: 0.2309369444847107 | D accuracy: 90.45449495315552] [G loss: [array(0.22936594, dtype=float32), array(0.22936594, dtype=float32), array(0.9051943, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
      "36 [D loss: 0.23002159595489502 | D accuracy: 90.62458872795105] [G loss: [array(0.22849828, dtype=float32), array(0.22849828, dtype=float32), array(0.9068668, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "37 [D loss: 0.2323729395866394 | D accuracy: 90.74558019638062] [G loss: [array(0.23087376, dtype=float32), array(0.23087376, dtype=float32), array(0.90805286, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "38 [D loss: 0.22814199328422546 | D accuracy: 90.91944694519043] [G loss: [array(0.22670713, dtype=float32), array(0.22670713, dtype=float32), array(0.9097656, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "39 [D loss: 0.2225431501865387 | D accuracy: 91.14230275154114] [G loss: [array(0.22117789, dtype=float32), array(0.22117789, dtype=float32), array(0.91196644, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "40 [D loss: 0.2172243297100067 | D accuracy: 91.3544774055481] [G loss: [array(0.21592622, dtype=float32), array(0.21592622, dtype=float32), array(0.9140625, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "41 [D loss: 0.2121841162443161 | D accuracy: 91.55672788619995] [G loss: [array(0.2109817, dtype=float32), array(0.2109817, dtype=float32), array(0.91606104, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "42 [D loss: 0.21027272939682007 | D accuracy: 91.5632963180542] [G loss: [array(0.21198879, dtype=float32), array(0.21198879, dtype=float32), array(0.91424006, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "43 [D loss: 0.20890259742736816 | D accuracy: 91.55011177062988] [G loss: [array(0.2081983, dtype=float32), array(0.2081983, dtype=float32), array(0.9157986, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "44 [D loss: 0.20497289299964905 | D accuracy: 91.71764850616455] [G loss: [array(0.20403539, dtype=float32), array(0.20403539, dtype=float32), array(0.91762906, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "45 [D loss: 0.20084232091903687 | D accuracy: 91.8948233127594] [G loss: [array(0.19984272, dtype=float32), array(0.19984272, dtype=float32), array(0.9193817, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "46 [D loss: 0.1968114823102951 | D accuracy: 92.06457138061523] [G loss: [array(0.19588362, dtype=float32), array(0.19588362, dtype=float32), array(0.9210612, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "47 [D loss: 0.1932489275932312 | D accuracy: 92.22736358642578] [G loss: [array(0.19263361, dtype=float32), array(0.19263361, dtype=float32), array(0.9226722, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "48 [D loss: 0.18992763757705688 | D accuracy: 92.38359928131104] [G loss: [array(0.18914297, dtype=float32), array(0.18914297, dtype=float32), array(0.9242188, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "49 [D loss: 0.18690407276153564 | D accuracy: 92.51829385757446] [G loss: [array(0.18604714, dtype=float32), array(0.18604714, dtype=float32), array(0.9255515, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "50 [D loss: 0.1834416389465332 | D accuracy: 92.66287088394165] [G loss: [array(0.18264148, dtype=float32), array(0.18264148, dtype=float32), array(0.9269832, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "51 [D loss: 0.1801186501979828 | D accuracy: 92.80197024345398] [G loss: [array(0.17933261, dtype=float32), array(0.17933261, dtype=float32), array(0.9283608, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "52 [D loss: 0.1769910752773285 | D accuracy: 92.9358959197998] [G loss: [array(0.1762646, dtype=float32), array(0.1762646, dtype=float32), array(0.9296875, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "53 [D loss: 0.17422734200954437 | D accuracy: 93.05065274238586] [G loss: [array(0.17348099, dtype=float32), array(0.17348099, dtype=float32), array(0.93082386, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "54 [D loss: 0.1711932122707367 | D accuracy: 93.1753158569336] [G loss: [array(0.17046833, dtype=float32), array(0.17046833, dtype=float32), array(0.93205917, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "55 [D loss: 0.16842114925384521 | D accuracy: 93.2818055152893] [G loss: [array(0.16771592, dtype=float32), array(0.16771592, dtype=float32), array(0.93311405, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "56 [D loss: 0.16565245389938354 | D accuracy: 93.39814186096191] [G loss: [array(0.1649521, dtype=float32), array(0.1649521, dtype=float32), array(0.9342672, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
      "57 [D loss: 0.16289713978767395 | D accuracy: 93.51052045822144] [G loss: [array(0.16223434, dtype=float32), array(0.16223434, dtype=float32), array(0.93538135, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "58 [D loss: 0.16023266315460205 | D accuracy: 93.61913204193115] [G loss: [array(0.15959401, dtype=float32), array(0.15959401, dtype=float32), array(0.93645835, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "59 [D loss: 0.15764126181602478 | D accuracy: 93.72417330741882] [G loss: [array(0.15700749, dtype=float32), array(0.15700749, dtype=float32), array(0.9375, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299ms/step\n",
      "60 [D loss: 0.15549278259277344 | D accuracy: 93.80050897598267] [G loss: [array(0.15487778, dtype=float32), array(0.15487778, dtype=float32), array(0.938256, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "61 [D loss: 0.1532842516899109 | D accuracy: 93.8744068145752] [G loss: [array(0.15269293, dtype=float32), array(0.15269293, dtype=float32), array(0.9389881, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "62 [D loss: 0.150959774851799 | D accuracy: 93.9704954624176] [G loss: [array(0.15039872, dtype=float32), array(0.15039872, dtype=float32), array(0.9399414, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "63 [D loss: 0.14868852496147156 | D accuracy: 94.0636157989502] [G loss: [array(0.1481441, dtype=float32), array(0.1481441, dtype=float32), array(0.9408654, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
      "64 [D loss: 0.146549791097641 | D accuracy: 94.15390491485596] [G loss: [array(0.14602828, dtype=float32), array(0.14602828, dtype=float32), array(0.9417614, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "65 [D loss: 0.14443568885326385 | D accuracy: 94.24148797988892] [G loss: [array(0.14393206, dtype=float32), array(0.14393206, dtype=float32), array(0.9426306, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "66 [D loss: 0.14238134026527405 | D accuracy: 94.32649612426758] [G loss: [array(0.14189628, dtype=float32), array(0.14189628, dtype=float32), array(0.9434743, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "67 [D loss: 0.1403895914554596 | D accuracy: 94.4090187549591] [G loss: [array(0.13991852, dtype=float32), array(0.13991852, dtype=float32), array(0.9442935, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "68 [D loss: 0.13855354487895966 | D accuracy: 94.47797536849976] [G loss: [array(0.13807622, dtype=float32), array(0.13807622, dtype=float32), array(0.9449777, dtype=float32)]]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "def train_gan(gan, generator, discriminator, data, epochs, batch_size, latent_dim, save_interval = 100):\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    gan_model_path = \"gan_models\"\n",
    "    if not os.path.exists(gan_model_path):\n",
    "        os.makedirs(gan_model_path)\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, data.shape[0], batch_size)\n",
    "        imgs = data[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        \n",
    "        discriminator.trainable = True\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        discriminator.trainable = False\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch(noise, valid)\n",
    "\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {100*d_loss[1]}] [G loss: {g_loss}]\")\n",
    "        if epoch % save_interval == 0:\n",
    "            generator.save(os.path.join(gan_model_path, f\"generator_{epoch}.keras\"))\n",
    "            discriminator.save(os.path.join(gan_model_path, f\"discriminator_{epoch}.keras\"))\n",
    "            gan.save(os.path.join(gan_model_path, f\"gan_{epoch}.keras\"))\n",
    "train_gan(gan, generator, discriminator, data, epochs=10000, batch_size=64, latent_dim=latent_dim)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
